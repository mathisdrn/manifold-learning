{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Locally Linear Embedding\n",
    "---\n",
    "\n",
    "### Main Concept\n",
    "\n",
    "LLE transforms high-dimensional data into a lower-dimensional space while preserving the local geometry of the data. The key insight is that each data point and its neighbors lie approximately on a locally linear patch of the manifold. \n",
    "\n",
    ":::{figure} ../assets/04 - patch.png\n",
    ":width: 400px\n",
    ":::\n",
    "\n",
    "The transformation occurs in three main steps:\n",
    "\n",
    "1. For each point $x_i$, find its $k$ nearest neighbors\n",
    "2. Compute weights $W_{ij}$ that best reconstruct each point from its neighbors\n",
    "3. Find low-dimensional points $y_i$ that are reconstructed by the same weights\n",
    "\n",
    "The transformation preserves local relationships while allowing the global structure to be unfolded into a lower-dimensional space.\n",
    "\n",
    "### Theoretical Aspect\n",
    "\n",
    "LLE involves two separate optimization problems:\n",
    "\n",
    "1. Weight Computation:\n",
    "$$\\min_W \\sum_i |x_i - \\sum_j W_{ij}x_j|^2$$\n",
    "Subject to constraints:\n",
    "- $W_{ij} = 0$ if $x_j$ is not a neighbor of $x_i$\n",
    "- $\\sum_j W_{ij} = 1$ for each $i$\n",
    "\n",
    "2. Embedding Computation:\n",
    "$$\\min_Y \\sum_i |y_i - \\sum_j W_{ij}y_j|^2$$\n",
    "Subject to constraints:\n",
    "- $\\sum_i y_i = 0$ (centered at origin)\n",
    "- $\\frac{1}{N}\\sum_i y_iy_i^T = I$ (unit covariance)\n",
    "\n",
    "The key variables being optimized are:\n",
    "- The weight matrix $W$ in the first step\n",
    "- The low-dimensional coordinates $Y$ in the second step\n",
    "\n",
    "### Solution Methodology\n",
    "\n",
    "The algorithm follows these main steps:\n",
    "\n",
    "1. Neighbor Search:\n",
    "   - Use k-nearest neighbors or Îµ-ball methods\n",
    "   - Typically employs efficient data structures like k-d trees\n",
    "\n",
    "2. Weight Computation:\n",
    "   - Solve local linear systems for each point\n",
    "   - Can be expressed as:\n",
    "   $W_i = \\arg\\min_w |x_i - \\sum_j w_jx_j|^2$\n",
    "   - Solution involves solving a small linear system with the Gram matrix\n",
    "\n",
    "3. Embedding Computation:\n",
    "   - The optimization reduces to an eigenvalue problem\n",
    "   - $M = (I-W)^T(I-W)$\n",
    "   - Find bottom eigenvectors of $M$ (excluding the zero eigenvalue)\n",
    "   - These eigenvectors provide the coordinates in the low-dimensional space\n",
    "\n",
    "### Global Optimality\n",
    "\n",
    "The LLE algorithm has interesting optimality properties:\n",
    "\n",
    "1. Weight Computation:\n",
    "   - This step is globally optimal for each local neighborhood\n",
    "   - The solution is obtained by solving a convex optimization problem\n",
    "\n",
    "2. Embedding Computation:\n",
    "   - The final embedding step has a global solution\n",
    "   - It reduces to an eigenvalue problem which can be solved exactly\n",
    "\n",
    "However, there are important limitations:\n",
    "\n",
    "1. Local Minima Issues:\n",
    "   - The choice of neighbors affects the final solution\n",
    "   - Different neighborhood sizes can lead to different embeddings\n",
    "\n",
    "2. Topological Limitations:\n",
    "   - Cannot handle cases where the manifold is not locally linear\n",
    "   - Struggles with holes or complex topological features\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The key mathematical advantage of LLE over many other methods is its ability to reduce the dimensionality reduction problem to two sequential convex optimization problems, making it computationally efficient and theoretically well-grounded. However, its reliance on local linearity assumptions can be a limitation in practice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
