{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Modified Locally Linear Embedding\n",
    "---\n",
    "\n",
    "### Main Concept\n",
    "\n",
    "Locally Linear Embedding (LLE) is based on a fundamental principle: while high-dimensional data may lie on a nonlinear manifold, each small neighborhood can be approximated as linear. The method preserves the geometric properties of these local neighborhoods while reducing dimensionality.\n",
    "\n",
    "The core idea relies on two key assumptions:\n",
    "1. Each data point can be reconstructed from its neighbors via linear combinations\n",
    "2. These same reconstruction relationships should be preserved in the lower-dimensional space\n",
    "\n",
    "To understand this transformation, consider a manifold $\\mathcal{M}$ embedded in $\\mathbb{R}^D$. LLE maps points $x_i \\in \\mathbb{R}^D$ to $y_i \\in \\mathbb{R}^d$ (where $d < D$) while preserving the local geometric relationships between neighboring points.\n",
    "\n",
    "### Theoretical Aspect\n",
    "\n",
    "The method involves two sequential optimization problems:\n",
    "\n",
    "1. First Optimization: Finding Reconstruction Weights\n",
    "$$\\min_{W} \\sum_{i=1}^N \\left\\|x_i - \\sum_{j=1}^N W_{ij}x_j\\right\\|^2$$\n",
    "\n",
    "Subject to constraints:\n",
    "- $W_{ij} = 0$ if $x_j$ is not a k-nearest neighbor of $x_i$\n",
    "- $\\sum_{j=1}^N W_{ij} = 1$ for each $i$ (affine reconstruction)\n",
    "\n",
    "2. Second Optimization: Computing Lower-dimensional Embeddings\n",
    "$$\\min_{Y} \\sum_{i=1}^N \\left\\|y_i - \\sum_{j=1}^N W_{ij}y_j\\right\\|^2$$\n",
    "\n",
    "Subject to constraints:\n",
    "- $\\frac{1}{N}\\sum_{i=1}^N y_i = 0$ (centered at origin)\n",
    "- $\\frac{1}{N}\\sum_{i=1}^N y_iy_i^T = I$ (unit covariance)\n",
    "\n",
    "The key variables being optimized are:\n",
    "- Weight matrix $W \\in \\mathbb{R}^{N \\times N}$\n",
    "- Embedded coordinates $Y \\in \\mathbb{R}^{N \\times d}$\n",
    "\n",
    "### Solution Methodology\n",
    "\n",
    "The solution process involves three main steps:\n",
    "\n",
    "1. Neighborhood Identification:\n",
    "- For each point $x_i$, identify its k nearest neighbors using Euclidean distance\n",
    "- Define neighborhood matrix $\\eta_{ij}$ where $\\eta_{ij} = 1$ if $x_j$ is a neighbor of $x_i$\n",
    "\n",
    "2. Weight Computation:\n",
    "- For each point $x_i$, solve the local optimization:\n",
    "$$\\min_{w_i} \\left\\|x_i - \\sum_{j \\in \\mathcal{N}_i} w_{ij}x_j\\right\\|^2$$\n",
    "- This reduces to solving the linear system:\n",
    "$$G_{jk}w_i = 1$$\n",
    "where $G_{jk} = (x_i - x_j)^T(x_i - x_k)$ is the local Gram matrix\n",
    "\n",
    "3. Embedding Computation:\n",
    "- Define matrix $M = (I-W)^T(I-W)$\n",
    "- The optimal embedding coordinates are given by the eigenvectors of $M$ corresponding to its smallest nonzero eigenvalues\n",
    "- If $\\lambda_0 \\leq \\lambda_1 \\leq ... \\leq \\lambda_N$ are eigenvalues of $M$, then:\n",
    "$Y = [\\nu_1, \\nu_2, ..., \\nu_d]$\n",
    "where $\\nu_i$ is the eigenvector corresponding to $\\lambda_i$\n",
    "\n",
    "### Global Optimality\n",
    "\n",
    "The optimization landscape has several important properties:\n",
    "\n",
    "1. Weight Computation:\n",
    "- Globally optimal solution exists for each local neighborhood\n",
    "- Solution uniqueness requires:\n",
    "  $\\text{rank}(G) = k-1$ where $k$ is the number of neighbors\n",
    "- Condition number $\\kappa(G)$ affects numerical stability\n",
    "\n",
    "2. Embedding Computation:\n",
    "- Global solution obtained via eigendecomposition\n",
    "- Uniqueness up to rotations and reflections\n",
    "- Solution quality depends on spectral gap $\\lambda_{d+1} - \\lambda_d$\n",
    "\n",
    "Limitations include:\n",
    "\n",
    "1. Topological Constraints:\n",
    "- Method assumes manifold is locally linear\n",
    "- Fails when:\n",
    "  $\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\gg 0$ (high curvature)\n",
    "  where $f$ describes the manifold\n",
    "\n",
    "2. Scale Dependencies:\n",
    "- Results sensitive to neighborhood size $k$\n",
    "- Optimal $k$ relates to local curvature:\n",
    "  $k \\sim \\mathcal{O}(\\log N)$ where $N$ is sample size\n",
    "\n",
    "3. Statistical Limitations:\n",
    "- Requires sufficient sampling density:\n",
    "  $N > \\mathcal{O}(d \\log d)$ where $d$ is intrinsic dimension\n",
    "- Performance degrades with noise:\n",
    "  $\\sigma_{noise} \\ll \\sigma_{data}$ required for stability\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The method provides global optimality for each step individually, but the combined solution depends critically on hyperparameter choices and data properties."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
